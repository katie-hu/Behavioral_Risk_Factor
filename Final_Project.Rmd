---
title: "Appendix"
author: "Lane Whitmore, Katie Hu, Sanjay Regi Philip"
date: "6/22/2022"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#### Read Data File
```{r}
df <- read.csv('2015.csv')
```


#### Data PreProcessing
```{r}
library(AppliedPredictiveModeling, quietly = T)
library(caret, quietly = T)
library(tidyr, quietly = T)
bhv.risk <- df
#subset specifically for HLTHPLN1 & State of California
bhv.risk <- subset(bhv.risk, HLTHPLN1 == 2 & X_STATE == 6)
bhv.riskspl <- subset(bhv.risk, select = c(1,27:74,90:97))
bhv.risk <- bhv.riskspl %>% drop_na(GENHLTH)
# dropping the single unsure response
bhv.risk <- bhv.risk[-1016,]
# data splitting
set.seed(444)
trainingRows <- createDataPartition(y=bhv.risk$GENHLTH, p=0.75, list = FALSE)
risk.train <- bhv.risk[trainingRows,]
risk.test <- bhv.risk[-trainingRows,]
```

#### Convert Feature Scaling
```{r, echo = FALSE}
library(dplyr, quietly = T)
## has outlier 2099 lbs
# weight in lbs
funcweight <- function(x, na.rm = FALSE) if_else(x>9000 & x<9999, true = round((x-9000)*2.2),
                                                 false = if_else(x==7777, true = NaN,
                                                                 false = if_else(x==9999,
                                                                                 true = NaN,
                                                                                 false = x)))
# height in inches
funcheight <- function(x, na.rm = FALSE) if_else(x>200 & x <711, 
                                                 true=as.numeric(substr(x,1,1))*12+as.numeric(substr(x,2,3)),
                                                 false = if_else(x > 9000 & x <9999, true= round((x-9000)*0.39370079),
                                                                 false = if_else(x==9999, true = NaN,
                                                                                 false =if_else(x==7777, 
                                                                                                true = NaN, 
                                                                                                false = x))))
# exercise a month
funcexer <- function(x, na.rm = FALSE) if_else(x > 100 & x < 200, true = (x-100)*4,
                                               false = if_else(x > 200 & x < 300, true = x - 200,
                                                               false = if_else(x==777, true = NaN,
                                                                               false = if_else(x==999,
                                                                                               true = NaN, 
                                                                                               false = x))))
# strength training a month
funcstrength <- function(x, na.rm = FALSE) if_else(x>200 & x <300, true = x-200,
                                                   false = if_else(x>100 & x<200,
                                                                   true = (x-100)*4,
                                                                   false = if_else(x==888,
                                                                                   true = 0,
                                                                                   false = if_else(x==777,
                                                                                                   true = NaN,
                                                                                                   false = if_else(x==999,true = NaN, false = x)))))
funcgenhlth <- function(x, na.rm = FALSE) if_else(x==7, true = NaN, false = x)
funchlth <- function(x, na.rm = FALSE) if_else(x==88, true = 0,false = if_else(x==77,true = NaN,
                                                                               false = if_else(x==99, true = NaN,
                                                                                               false=x)))
funcage <- function(x, na.rm = FALSE) if_else(x == 98 | x == 99, true = NaN, false = x)
funcexhmm <- function(x, na.rm = FALSE) if_else(x==777, 
                                                true = NaN, 
                                                false = if_else(x==999,
                                                                true = NaN,
                                                                false = x))
funcchild <- function(x, na.rm = FALSE) if_else(x == 88, true = 0, false = if_else(x==99,
                                                                                   true = NaN,
                                                                                   false = x))
# Want to make a third option that shows all nonresponses whether they be null or refusal
funcbin <- function(x, na.rm = TRUE) if_else(is.na(x), true= 0, 
                                             false = if_else(x== 7 | x== 9,true = 0,
                                                             false = x))
funcmultifact <- function(x, na.rm = TRUE) if_else(is.na(x), true = 0,
                                                   false = if_else(x==77 |x==99,
                                                                   true = NaN,
                                                                   false = x))
```


##### Description goes here
```{r}
bhv.train.fixed <- risk.train %>%
  mutate_at(40, funcweight)%>%
  mutate_at(41, funcheight)%>%
  mutate_at(c(52,55), funcexer)%>%
  mutate_at(57,funcstrength)%>%
  mutate_at(c(7:26,29:35,39,42:50),funcbin)%>%
  mutate_at(c(27),funcage)%>%
  mutate_at(c(38,51,54), funcmultifact)%>%
  mutate_at(c(53,56), funcexhmm)%>%
  mutate_at(c(3:5), funchlth)%>%
  mutate_at(37, funcchild)%>%
  mutate_at(3, funcchild)%>%
  mutate_at(2, funcgenhlth)%>%
  mutate_at(2, as.factor)
bhv.test.fixed <- risk.test %>%
  mutate_at(40, funcweight)%>%
  mutate_at(41, funcheight)%>%
  mutate_at(c(52,55), funcexer)%>%
  mutate_at(57,funcstrength)%>%
  mutate_at(c(7:26,29:35,39,42:50),funcbin)%>%
  mutate_at(c(27),funcage)%>%
  mutate_at(c(38,51,54), funcmultifact)%>%
  mutate_at(c(53,56), funcexhmm)%>%
  mutate_at(c(3:5), funchlth)%>%
  mutate_at(37, funcchild)%>%
  mutate_at(2, funcgenhlth)%>%
  mutate_at(2, as.factor)
```


##### Description goes here
```{r}
sapply(bhv.train.fixed, function(x) sum(is.na(x)))
bhv.train.filled <- sapply(bhv.train.fixed, function(x) ifelse(is.na(x), median(x, na.rm=TRUE), x))
bhv.test.filled <- sapply(bhv.test.fixed, function(x) ifelse(is.na(x), median(x, na.rm=TRUE), x))
bhv.train.filled <- data.frame(bhv.train.filled)
bhv.test.filled <- data.frame(bhv.test.filled)
sapply(bhv.train.filled, function(x) sum(is.na(x)))
```


#### Remove near-zero variance columns
```{r}
degeneratePredictors <- nearZeroVar(bhv.train.filled)
bhv.train.nzv <- bhv.train.filled[,-degeneratePredictors]
bhv.test.nzv <- bhv.test.filled[,-degeneratePredictors]
```


#### Remove highly correlated variables
```{r}
num_colsdr <- unlist(lapply(bhv.train.nzv, is.numeric))
numeric.cor <- cor(bhv.train.nzv[,-1])
corrplot::corrplot(numeric.cor, order = 'hclust', tl.cex = 0.6)
numeric.high <- findCorrelation(numeric.cor, cutoff = .85)
# One single GENHLTH through the EDA below was found to have 7 for non response
# This value was removed as we would like to predict Health. 
bhv.train.cor.nzv <- bhv.train.nzv[, -numeric.high]
bhv.test.cor.nzv <- bhv.test.nzv[, -numeric.high]
corrplot::corrplot(cor(bhv.train.cor.nzv), order = 'hclust', tl.cex = 0.6)
```

#### EDA
```{r}
library(ggplot2)
par(mfrow=c(2,3))
boxplot(bhv.train.cor.nzv$HEIGHT3 ~ bhv.train.cor.nzv$GENHLTH,
        ylab = 'Height in Inches',
        xlab = 'General Health')
boxplot(bhv.train.cor.nzv$WEIGHT2 ~ bhv.train.cor.nzv$GENHLTH,
        ylab = 'Weight in Pounds',
        xlab = 'General Health')
boxplot(bhv.train.cor.nzv$EXERHMM1 ~ bhv.train.cor.nzv$GENHLTH,
        ylab = 'Hours Exercised Last Month',
        xlab = 'General Health')
boxplot(bhv.train.cor.nzv$PHYSHLTH ~ bhv.train.cor.nzv$MEDCOST,
        ylab = 'Days Poor Physical Health Last Month',
        xlab = 'Could not Afford last Medical Trip')
boxplot(bhv.train.cor.nzv$MENTHLTH ~ bhv.train.cor.nzv$MEDCOST,
        ylab = 'Days Poor Mental Health Last Month',
        xlab = 'Could not Afford last Medical Trip')
boxplot(bhv.train.cor.nzv$WEIGHT2 ~ bhv.train.cor.nzv$DIABETE3,
        ylab = 'Weight in Pounds',
        xlab = 'Diabetes Yes/Yes/No/NoPreDia')
```


```{r}
General_Health <- as.factor(bhv.train.cor.nzv$GENHLTH)
ggplot(bhv.train.cor.nzv, aes(x = WEIGHT2, y = HEIGHT3,
                              color = as.factor(DIABETE3))) +
  ylab("Height in Inches")+
  xlab("Weight in Pounds")+
  geom_point(size = 2)+
  scale_color_discrete(labels = c('No Response','Yes','Yes Preg','No','No/Pre'),
                       type = c('royalblue3','indianred3','plum3','darkseagreen4',
                                'sienna3'))
ggplot(bhv.train.cor.nzv, aes(x = WEIGHT2, y = HEIGHT3,
                              color = General_Health)) +
  ylab("Height in Inches")+
  xlab("Weight in Pounds")+
  geom_point(size = 2)+
  scale_color_discrete(labels = c('Excellent','Very Good','Good','Fair','Poor'),
                       type = c('royalblue3','indianred3','plum3','darkseagreen4',
                                'sienna3'))
ggplot(bhv.train.cor.nzv, aes(y= EXERHMM1, x=MENTHLTH, 
                              color = General_Health))+
  ylab('Hours Exercised in the Last Month')+
  xlab('Poor Mental Health Days')+
  geom_point(size=2)+
  scale_color_discrete(labels = c('Excellent','Very Good','Good','Fair','Poor'),
                       type = c('royalblue3','indianred3','plum3','darkseagreen4',
                                'sienna3'))
```


```{r}
par(mfrow=c(2,4))
hist(bhv.train.cor.nzv$WEIGHT2, 
     xlab = 'Weight in Pounds',
     main = 'Weight',
     col = 'lightblue',
     border = 'black')
hist(bhv.train.cor.nzv$HEIGHT3, 
     xlab = 'Height in Inches',
     main = 'Height',
     col = 'lightblue',
     border = 'black')
hist(bhv.train.cor.nzv$GENHLTH, 
     xlab = 'General Health',
     main = 'General Health',
     col = 'lightblue',
     border = 'black')
hist(bhv.train.cor.nzv$EXEROFT1, 
     xlab = 'Exercise Last Month',
     main = 'Exercise Last Month',
     col = 'lightblue',
     border = 'black')
hist(bhv.train.cor.nzv$EXEROFT2, 
     xlab = 'Exercise Last Month',
     main = 'Exercise Last Month',
     col = 'lightblue',
     border = 'black')
hist(bhv.train.cor.nzv$EXERHMM2, 
     xlab = 'Exercise Hours Last Month',
     main = 'Exer. Hours Last Month',
     col = 'lightblue',
     border = 'black')
hist(bhv.train.cor.nzv$DIABETE3, 
     xlab = 'Diabetes Yes/Yes/No/No',
     main = 'Diabetes',
     col = 'lightblue',
     border = 'black')
hist(bhv.train.cor.nzv$STRENGTH, 
     xlab = 'Strength Training Per Month',
     main = 'Strength',
     col = 'lightblue',
     border = 'black')
```


### Feature Selection

```{r}
# Train and Test Variables
bhv_train <- bhv.train.cor.nzv
bhv_test <- bhv.test.cor.nzv
```

```{r}
# Check data types
sapply(bhv_train, function(x) typeof(x))
```

```{r}
# Check data type class
print('Before factor convert')
sapply(bhv_train, class)

# convert GENHLTH to factor for classification
bhv_train[,1] <- as.factor(bhv_train[,1])
bhv_test[,1] <- as.factor(bhv_test[,1])

# verify to make sure GENHLTH was changed to factor
print('After factor convert')
sapply(bhv_train, class)
```

```{r initial accuracy}
# Baseline Accuracy

ratio_1 <- ((length(bhv_test$GENHLTH[bhv_test$GENHLTH == 1]) / length(bhv_test$GENHLTH)))
ratio_1
 
ratio_2 <- ((length(bhv_test$GENHLTH[bhv_test$GENHLTH == 2]) / length(bhv_test$GENHLTH)))
ratio_2

ratio_3 <- ((length(bhv_test$GENHLTH[bhv_test$GENHLTH == 3]) / length(bhv_test$GENHLTH)))
ratio_3

ratio_4 <- ((length(bhv_test$GENHLTH[bhv_test$GENHLTH == 4]) / length(bhv_test$GENHLTH)))
ratio_4

ratio_5 <- ((length(bhv_test$GENHLTH[bhv_test$GENHLTH == 5]) / length(bhv_test$GENHLTH)))
ratio_5


b_acc <- (ratio_1**2 + ratio_2**2 + ratio_3**2 + ratio_4**2 + ratio_5**2)*100
print(paste0('The baseline accuracy of GENHLTH is: ', round(b_acc, 2), '%'))
```

```{r}
# Add Pre-Processing with center, scale, and medianImpute
trainimp <- preProcess(bhv_train, method = c("medianImpute", "center", "scale"))
trainpr <- predict(trainimp, bhv_train)
testpr <- predict(trainimp, bhv_test)
# summary(trainpr)
# summary(testpr)
ctrl <- trainControl(method = "cv", classProbs = TRUE)

# Rename Factor Levels
levels(trainpr$GENHLTH) <- c('Excellent', 'Very_Good', 'Good', 'Fair', 'Poor')
levels(testpr$GENHLTH) <- c('Excellent', 'Very_Good', 'Good', 'Fair', 'Poor')
```


#### Model Building for Identifying Important Variables

#### Random Forest
```{r rf}
# Random Forest Feature Importance
library(caret)
library(randomForest)
rf <- train(x = trainpr[,-1], 
               y = trainpr$GENHLTH,
               method = "rf",
               ntree = 1000,
               metric = "Accuracy",
               trControl = ctrl)

# Feature Importance
var <- varImp(rf, scale = FALSE)
plot(var, top = 20, main = "Random Forest - Top 20 Variables by Importance" )
```

#### CART
```{r cart}
# CART Feature Importance
library(rpart)
cart <- rpart(GENHLTH ~., data = trainpr)

# Feature importance
cart_var <- varImp(cart, scale = FALSE)
cart_var[order(cart_var$Overall, decreasing = TRUE),]
```

### Final Features Selected
```{r}
# Dropping predictors with low importance based on common low feature importance across both models
train <- subset(trainpr, select = -c(PREGNANT, CPDEMO1, EXRACT21, EXERANY2, PERSDOC2))
test <- subset(testpr, select = -c(PREGNANT, CPDEMO1, EXRACT21, EXERANY2, PERSDOC2))
```


#### Model Building
#### Establish Control for Model Building
```{r control}
# Establish Control
ctrl <- trainControl(method = "cv", classProbs = TRUE)

library(caret)
```


#### Random Forests
```{r random forests}
mtryValues <- seq(1,10,1)
ctrl <- trainControl(method = "cv", classProbs = TRUE)
set.seed(100)
rfFit <- train(x = train[,-1], 
               y = train$GENHLTH,
               method = "rf",
               ntree = 1000,
               tuneGrid = data.frame(mtry = mtryValues),
               metric = "Accuracy",
               trControl = ctrl)
rfCM <- confusionMatrix(rfFit, norm = "none")
rfImp <- varImp(rfFit, scale = FALSE)
```

#### Knn
```{r k-NN}
set.seed(100)
knnTune <- train(x = train[,-1], 
                 y = train$GENHLTH,
                 method = "knn",
                 tuneLength = 10,
                 metric = "Accuracy",
                 trControl = ctrl)
knnCM <- confusionMatrix(knnTune, norm = "none")
knn_var <- varImp(knnTune, scale = FALSE)
```

#### Neural Networks
```{r Neural Networks, warning=FALSE}
library(caret)
set.seed(100)
nnetGrid <- expand.grid(size=1:3, decay=c(0,0.1,0.2,0.3,0.4,0.5,1,2))
set.seed(100)
nnetTune <- train(x = train[,-1], 
                  y = train$GENHLTH,
                  method = "nnet",
                  tuneGrid = nnetGrid,
                  metric = "Accuracy",
                  trace = FALSE, 
                  maxit = 2000, 
                  trControl = ctrl)
nnetCM <- confusionMatrix(nnetTune, norm = "none")
nnet_var <- varImp(nnetTune, scale = FALSE)
```

#### Nearest Shrunken Centroids
```{r NSC}
set.seed(100)
nscTUNE <- train(x = train[,-1], 
                 y = train$GENHLTH,
                 method = "pam",
                 tuneGrid = data.frame(threshold = seq(0, 25, length = 30)),
                 metric = "Accuracy",
                 trControl = ctrl)
nscCM <- confusionMatrix(nscTUNE, norm = "none")
nsc_var <- varImp(nscTUNE, scale = FALSE)
```





#### Model Results

```{r ModelResults}
# Predictor Importance
plot(rfImp, top = 10)
plot(knn_var, top = 10)
#plot(nnet_var, top = 10)
plot(nsc_var, top = 10)
# Confusion Matrices and Accuracy Values of Training Data
print("Confusion Matrix for Random Forests Trained Model")
rfCM 
print("Confusion Matrix for Knn Trained Model")
knnCM
print("Confusion Matrix for Nnet Trained Model")
nnetCM
print("Confusion Matrix for NSC Trained Model")
nscCM
# Test Results
testResults <- data.frame(obs = test$GENHLTH,
                          rf = predict(rfFit, test[,-1]))
testResults$knn <- predict(knnTune, test[,-1])
testResults$nnet <- predict(nnetTune, test[,-1])
testResults$nsc <- predict(nscTUNE, test[,-1])
print("Confusion Matrix for Random Forests Test Model")
confusionMatrix(testResults$rf, testResults$obs)
print("Confusion Matrix for Knn Test Model")
confusionMatrix(testResults$knn, testResults$obs)
print("Confusion Matrix for Nnet Test Model")
confusionMatrix(testResults$nnet, testResults$obs)
print("Confusion Matrix for NSC Test Model")
confusionMatrix(testResults$nsc, testResults$obs)
```